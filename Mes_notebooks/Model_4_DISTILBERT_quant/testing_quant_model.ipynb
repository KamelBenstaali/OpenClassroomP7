{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff40290c",
   "metadata": {},
   "source": [
    "In this notebook, our goal is to test the performance of the dynamic onnx model ```model-int8-dynamic.onnx``` to check if we can still deploy it on our ASP machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3d3b03",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b71444ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "if \"__file__\" in globals():\n",
    "    ROOT = Path(__file__).resolve().parent\n",
    "else:\n",
    "    ROOT = Path.cwd()\n",
    "    nb_root = ROOT / \"Mes_notebooks\" / \"Model_4_DISTILBERT_quant\"\n",
    "    if nb_root.exists():\n",
    "        ROOT = nb_root\n",
    "MODEL_PACKAGE_DIR = ROOT.parent / \"Model_4_DISTILBERT\" / \"distilbert_model_package\"\n",
    "DEFAULT_MODEL_PATH = ROOT / \"model-int8-dynamic.onnx\"\n",
    "\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 1  # modÃ¨le quantifiÃ© exportÃ© avec batch statique ; on force 1 par dÃ©faut\n",
    "VALID_EVAL_LABELS = {\"positive\", \"negative\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253f9195",
   "metadata": {},
   "source": [
    "# Preprocessing and loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b432899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tweet(t: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", t.strip())\n",
    "\n",
    "def load_label_map() -> Dict[int, str]:\n",
    "    \"\"\"Read id2label from the saved HF config if available.\"\"\"\n",
    "    cfg_path = MODEL_PACKAGE_DIR / \"hf_model\" / \"config.json\"\n",
    "    if not cfg_path.exists():\n",
    "        return {0: \"negative\", 1: \"positive\"}\n",
    "\n",
    "    try:\n",
    "        cfg = json.loads(cfg_path.read_text())\n",
    "        id2label = cfg.get(\"id2label\") or {}\n",
    "        mapped = {int(k): str(v).lower() for k, v in id2label.items()}\n",
    "        return mapped or {0: \"negative\", 1: \"positive\"}\n",
    "    except Exception:\n",
    "        return {0: \"negative\", 1: \"positive\"}\n",
    "\n",
    "def load_tokenizer():\n",
    "    return AutoTokenizer.from_pretrained(MODEL_PACKAGE_DIR / \"tokenizer\", use_fast=True)\n",
    "\n",
    "def softmax(logits: np.ndarray) -> np.ndarray:\n",
    "    shifted = logits - logits.max(axis=-1, keepdims=True)\n",
    "    exp = np.exp(shifted)\n",
    "    return exp / exp.sum(axis=-1, keepdims=True)\n",
    "\n",
    "def prepare_ort_inputs(session: ort.InferenceSession, encoded: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n",
    "    base = encoded[\"input_ids\"]\n",
    "    ort_inputs: Dict[str, np.ndarray] = {}\n",
    "    for meta in session.get_inputs():\n",
    "        name = meta.name\n",
    "        if name in encoded:\n",
    "            ort_inputs[name] = encoded[name]\n",
    "        elif name == \"token_type_ids\":\n",
    "            ort_inputs[name] = np.zeros_like(base)\n",
    "        elif name == \"position_ids\":\n",
    "            ort_inputs[name] = np.arange(base.shape[1], dtype=np.int64)[None, :].repeat(base.shape[0], axis=0)\n",
    "        else:\n",
    "            raise KeyError(f\"Impossible de fournir l'entrÃ©e ONNX {name}\")\n",
    "    return ort_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8eab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_onnx_inference(\n",
    "    session: ort.InferenceSession,\n",
    "    tokenizer,\n",
    "    texts: List[str],\n",
    "    max_length: int,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    encoded = tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "    ort_inputs = prepare_ort_inputs(session, encoded)\n",
    "    logits = session.run(None, ort_inputs)[0]\n",
    "    probs = softmax(logits)\n",
    "    pred_ids = probs.argmax(axis=-1)\n",
    "    pred_scores = probs.max(axis=-1)\n",
    "    return pred_ids, pred_scores\n",
    "\n",
    "\n",
    "def evaluate_dataset(\n",
    "    session: ort.InferenceSession,\n",
    "    tokenizer,\n",
    "    label_map: Dict[int, str],\n",
    "    dataset: Iterable[Dict[str, str]],\n",
    "    batch_size: int,\n",
    "    max_length: int,\n",
    "    show_category_accuracy: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    dataset = list(dataset)\n",
    "    rows = []\n",
    "\n",
    "    normalized_texts = [normalize_tweet(item[\"tweet\"]) for item in dataset]\n",
    "    raw_texts = [item[\"tweet\"] for item in dataset]\n",
    "    expected_labels = [item[\"label\"].lower() for item in dataset]\n",
    "    categories = [item[\"category\"] for item in dataset]\n",
    "\n",
    "    for start in range(0, len(dataset), batch_size):\n",
    "        stop = start + batch_size\n",
    "        batch_texts = normalized_texts[start:stop]\n",
    "        pred_ids, pred_scores = run_onnx_inference(session, tokenizer, batch_texts, max_length)\n",
    "\n",
    "        for idx, score, raw_tweet, expected, category in zip(\n",
    "            pred_ids,\n",
    "            pred_scores,\n",
    "            raw_texts[start:stop],\n",
    "            expected_labels[start:stop],\n",
    "            categories[start:stop],\n",
    "        ):\n",
    "            predicted_label = label_map.get(int(idx), str(idx))\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"category\": category,\n",
    "                    \"tweet\": raw_tweet,\n",
    "                    \"label_attendue\": expected,\n",
    "                    \"prediction\": predicted_label,\n",
    "                    \"score\": round(float(score), 4),\n",
    "                    \"ok\": predicted_label == expected if expected in VALID_EVAL_LABELS else None,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    filtered = df[df[\"label_attendue\"].isin(VALID_EVAL_LABELS)]\n",
    "    global_acc = (filtered[\"label_attendue\"] == filtered[\"prediction\"]).mean()\n",
    "    print(f\"\\nðŸŽ¯ Accuracy globale (pos/neg) : {global_acc:.4f}\")\n",
    "\n",
    "    if show_category_accuracy and not filtered.empty:\n",
    "        print(\"\\nðŸ“Š Accuracy par catÃ©gorie :\")\n",
    "        cat_acc = (\n",
    "            filtered.groupby(\"category\")\n",
    "            .apply(lambda g: (g[\"label_attendue\"] == g[\"prediction\"]).mean())\n",
    "        )\n",
    "        print(cat_acc)\n",
    "    return df\n",
    "\n",
    "\n",
    "def _infer_static_batch(session: ort.InferenceSession) -> int | None:\n",
    "    \"\"\"Detect a fixed batch dimension in the ONNX inputs, if any.\"\"\"\n",
    "    for meta in session.get_inputs():\n",
    "        if not meta.shape:\n",
    "            continue\n",
    "        dim0 = meta.shape[0]\n",
    "        if isinstance(dim0, int) and dim0 > 0:\n",
    "            return dim0\n",
    "    return None\n",
    "\n",
    "\n",
    "def choose_batch_size(session: ort.InferenceSession, requested: int) -> int:\n",
    "    static_batch = _infer_static_batch(session)\n",
    "    if static_batch is not None and static_batch != requested:\n",
    "        print(\n",
    "            f\"âš ï¸  Le modÃ¨le semble figÃ© sur batch={static_batch}. \"\n",
    "            f\"Batch demandÃ©={requested} => utilisation batch={static_batch}\"\n",
    "        )\n",
    "        return static_batch\n",
    "    return requested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0077a5e",
   "metadata": {},
   "source": [
    "# Testing on tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea035522",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_tweets_dataset = [\n",
    "\n",
    "    # 1 â€” Sarcasme negatif\n",
    "    {\"category\": \"sarcasme\", \"tweet\": \"Great job @AirParadis, another â€˜on-timeâ€™ departureâ€¦ only 3 hours late. Truly impressive ðŸ™ƒ\", \"label\": \"negative\"},\n",
    "    {\"category\": \"sarcasme\", \"tweet\": \"Loved waiting at the gate for an eternity. Really, I had nothing better to do today ðŸ˜‚\", \"label\": \"negative\"},\n",
    "    {\"category\": \"sarcasme\", \"tweet\": \"Oh wow, free water after canceling my flight. The generosity is unreal ðŸ˜’\", \"label\": \"negative\"},\n",
    "    {\"category\": \"sarcasme\", \"tweet\": \"Fantastic! My luggage is on holiday in Paris while I'm stuck here. Amazing service!\", \"label\": \"negative\"},\n",
    "    {\"category\": \"sarcasme\", \"tweet\": \"Thanks @AirParadis for this unforgettable disaster of a flight.\", \"label\": \"negative\"},\n",
    "\n",
    "    # 2 â€” AmbiguÃ¯tÃ© volontaire (converted to negative or positive clearly)\n",
    "    {\"category\": \"ambiguite\", \"tweet\": \"This flight felt terrible from start to finish.\", \"label\": \"negative\"},\n",
    "    {\"category\": \"ambiguite\", \"tweet\": \"Honestly, this was a pretty good flight overall.\", \"label\": \"positive\"},\n",
    "    {\"category\": \"ambiguite\", \"tweet\": \"I expected a lot better than what I got today.\", \"label\": \"negative\"},\n",
    "    {\"category\": \"ambiguite\", \"tweet\": \"The service was surprisingly pleasant, well done @AirParadis!\", \"label\": \"positive\"},\n",
    "    {\"category\": \"ambiguite\", \"tweet\": \"Iâ€™m definitely not flying with them again after today.\", \"label\": \"negative\"},\n",
    "\n",
    "    # 3 â€” Double nÃ©gation (converted)\n",
    "    {\"category\": \"double_neg\", \"tweet\": \"I canâ€™t say the flight was bad â€” it was actually very good.\", \"label\": \"positive\"},\n",
    "    {\"category\": \"double_neg\", \"tweet\": \"I wouldnâ€™t say I enjoyed the flightâ€¦ because I didnâ€™t.\", \"label\": \"negative\"},\n",
    "    {\"category\": \"double_neg\", \"tweet\": \"Not unhappy means nothing, Iâ€™m definitely upset with this airline.\", \"label\": \"negative\"},\n",
    "    {\"category\": \"double_neg\", \"tweet\": \"It wasnâ€™t not comfortable â€” it was genuinely great!\", \"label\": \"positive\"},\n",
    "    {\"category\": \"double_neg\", \"tweet\": \"I wouldnâ€™t say I donâ€™t recommend @AirParadis, it's a solid choice.\", \"label\": \"positive\"},\n",
    "\n",
    "    # 4 â€” Mixed feelings complexes (converted)\n",
    "    {\"category\": \"mixed_complex\", \"tweet\": \"The landing was smooth and the staff was incredibly kind. Great flight!\", \"label\": \"positive\"},\n",
    "    {\"category\": \"mixed_complex\", \"tweet\": \"Terrible turbulence and awful food, I hated the whole experience.\", \"label\": \"negative\"},\n",
    "    {\"category\": \"mixed_complex\", \"tweet\": \"My kids enjoyed it, but I honestly found it stressful and unpleasant.\", \"label\": \"negative\"},\n",
    "    {\"category\": \"mixed_complex\", \"tweet\": \"The upgrade was amazing and made the whole trip enjoyable.\", \"label\": \"positive\"},\n",
    "    {\"category\": \"mixed_complex\", \"tweet\": \"Losing my bag ruined everything today.\", \"label\": \"negative\"},\n",
    "\n",
    "    # 5 â€” Positif qui semble nÃ©gatif / inverse (converted clearly)\n",
    "    {\"category\": \"pos_neg\", \"tweet\": \"The flight was long but honestly quite enjoyable.\", \"label\": \"positive\"},\n",
    "    {\"category\": \"pos_neg\", \"tweet\": \"My seat didnâ€™t recline and it hurt my back. Terrible comfort.\", \"label\": \"negative\"},\n",
    "    {\"category\": \"pos_neg\", \"tweet\": \"The chaos was stressful and I didnâ€™t enjoy this flight at all.\", \"label\": \"negative\"},\n",
    "    {\"category\": \"pos_neg\", \"tweet\": \"The delay was annoying and ruined my entire schedule.\", \"label\": \"negative\"},\n",
    "    {\"category\": \"pos_neg\", \"tweet\": \"Surprisingly, the trip was comfortable and relaxing.\", \"label\": \"positive\"},\n",
    "\n",
    "    # 6 â€” Implicite (kept negative)\n",
    "    {\"category\": \"implicite\", \"tweet\": \"I donâ€™t even have the energy to complain anymore.\", \"label\": \"negative\"},\n",
    "    {\"category\": \"implicite\", \"tweet\": \"It happened againâ€¦ another terrible experience.\", \"label\": \"negative\"},\n",
    "    {\"category\": \"implicite\", \"tweet\": \"Iâ€™m not mad. Iâ€™m extremely disappointed.\", \"label\": \"negative\"},\n",
    "    {\"category\": \"implicite\", \"tweet\": \"No words. Just a horrible flight.\", \"label\": \"negative\"},\n",
    "    {\"category\": \"implicite\", \"tweet\": \"Silence says it all â€” this was awful.\", \"label\": \"negative\"},\n",
    "\n",
    "    # 7 â€” Sarcasme positif (kept positive)\n",
    "    {\"category\": \"sarcasme_positif\", \"tweet\": \"Wow, @AirParadis took off on time. Miracles do happen!\", \"label\": \"positive\"},\n",
    "    {\"category\": \"sarcasme_positif\", \"tweet\": \"Not getting bumped from my seat today? Incredible!\", \"label\": \"positive\"},\n",
    "    {\"category\": \"sarcasme_positif\", \"tweet\": \"Flight attendants actually smiled. Impressive!\", \"label\": \"positive\"},\n",
    "    {\"category\": \"sarcasme_positif\", \"tweet\": \"A full flight without any issues? Amazing!\", \"label\": \"positive\"},\n",
    "    {\"category\": \"sarcasme_positif\", \"tweet\": \"The plane landed earlyâ€¦ surprisingly good job.\", \"label\": \"positive\"},\n",
    "\n",
    "    # 8 â€” Positif en surface mais fond nÃ©gatif (negative)\n",
    "    {\"category\": \"pos_surface_neg_fond\", \"tweet\": \"Iâ€™m â€˜thrilledâ€™ that my flight was delayed again. Awful service.\", \"label\": \"negative\"},\n",
    "    {\"category\": \"pos_surface_neg_fond\", \"tweet\": \"Consistently disappointing, as always.\", \"label\": \"negative\"},\n",
    "    {\"category\": \"pos_surface_neg_fond\", \"tweet\": \"The announcements were useless and the whole trip was terrible.\", \"label\": \"negative\"},\n",
    "    {\"category\": \"pos_surface_neg_fond\", \"tweet\": \"Free snack but still not getting home today? Terrible airline.\", \"label\": \"negative\"},\n",
    "    {\"category\": \"pos_surface_neg_fond\", \"tweet\": \"Great, another delay. This airline is exhausting.\", \"label\": \"negative\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105b06b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du modÃ¨le ONNX: /home/kamel/Openclassroom_projets/P7/Mes_notebooks/Model_4_DISTILBERT_quant/model-int8-dynamic.onnx\n",
      "\n",
      "Ã‰valuation sur 40 tweets difficiles...\n",
      "\n",
      "ðŸŽ¯ Accuracy globale (pos/neg) : 0.8250\n",
      "\n",
      "ðŸ“Š Accuracy par catÃ©gorie :\n",
      "category\n",
      "ambiguite               1.0\n",
      "double_neg              0.6\n",
      "implicite               1.0\n",
      "mixed_complex           1.0\n",
      "pos_neg                 1.0\n",
      "pos_surface_neg_fond    1.0\n",
      "sarcasme                0.0\n",
      "sarcasme_positif        1.0\n",
      "dtype: float64\n",
      "\n",
      "RÃ©sultats dÃ©taillÃ©s :\n",
      "                category                                              tweet  \\\n",
      "0               sarcasme  Great job @AirParadis, another â€˜on-timeâ€™ depar...   \n",
      "1               sarcasme  Loved waiting at the gate for an eternity. Rea...   \n",
      "2               sarcasme  Oh wow, free water after canceling my flight. ...   \n",
      "3               sarcasme  Fantastic! My luggage is on holiday in Paris w...   \n",
      "4               sarcasme  Thanks @AirParadis for this unforgettable disa...   \n",
      "5              ambiguite    This flight felt terrible from start to finish.   \n",
      "6              ambiguite   Honestly, this was a pretty good flight overall.   \n",
      "7              ambiguite     I expected a lot better than what I got today.   \n",
      "8              ambiguite  The service was surprisingly pleasant, well do...   \n",
      "9              ambiguite  Iâ€™m definitely not flying with them again afte...   \n",
      "10            double_neg  I canâ€™t say the flight was bad â€” it was actual...   \n",
      "11            double_neg  I wouldnâ€™t say I enjoyed the flightâ€¦ because I...   \n",
      "12            double_neg  Not unhappy means nothing, Iâ€™m definitely upse...   \n",
      "13            double_neg  It wasnâ€™t not comfortable â€” it was genuinely g...   \n",
      "14            double_neg  I wouldnâ€™t say I donâ€™t recommend @AirParadis, ...   \n",
      "15         mixed_complex  The landing was smooth and the staff was incre...   \n",
      "16         mixed_complex  Terrible turbulence and awful food, I hated th...   \n",
      "17         mixed_complex  My kids enjoyed it, but I honestly found it st...   \n",
      "18         mixed_complex  The upgrade was amazing and made the whole tri...   \n",
      "19         mixed_complex             Losing my bag ruined everything today.   \n",
      "20               pos_neg  The flight was long but honestly quite enjoyable.   \n",
      "21               pos_neg  My seat didnâ€™t recline and it hurt my back. Te...   \n",
      "22               pos_neg  The chaos was stressful and I didnâ€™t enjoy thi...   \n",
      "23               pos_neg  The delay was annoying and ruined my entire sc...   \n",
      "24               pos_neg  Surprisingly, the trip was comfortable and rel...   \n",
      "25             implicite  I donâ€™t even have the energy to complain anymore.   \n",
      "26             implicite    It happened againâ€¦ another terrible experience.   \n",
      "27             implicite           Iâ€™m not mad. Iâ€™m extremely disappointed.   \n",
      "28             implicite                  No words. Just a horrible flight.   \n",
      "29             implicite              Silence says it all â€” this was awful.   \n",
      "30      sarcasme_positif  Wow, @AirParadis took off on time. Miracles do...   \n",
      "31      sarcasme_positif  Not getting bumped from my seat today? Incredi...   \n",
      "32      sarcasme_positif     Flight attendants actually smiled. Impressive!   \n",
      "33      sarcasme_positif         A full flight without any issues? Amazing!   \n",
      "34      sarcasme_positif     The plane landed earlyâ€¦ surprisingly good job.   \n",
      "35  pos_surface_neg_fond  Iâ€™m â€˜thrilledâ€™ that my flight was delayed agai...   \n",
      "36  pos_surface_neg_fond             Consistently disappointing, as always.   \n",
      "37  pos_surface_neg_fond  The announcements were useless and the whole t...   \n",
      "38  pos_surface_neg_fond  Free snack but still not getting home today? T...   \n",
      "39  pos_surface_neg_fond  Great, another delay. This airline is exhausting.   \n",
      "\n",
      "   label_attendue prediction   score     ok  \n",
      "0        negative   positive  1.0000  False  \n",
      "1        negative   positive  0.9998  False  \n",
      "2        negative   positive  1.0000  False  \n",
      "3        negative   positive  1.0000  False  \n",
      "4        negative   positive  0.9965  False  \n",
      "5        negative   negative  1.0000   True  \n",
      "6        positive   positive  1.0000   True  \n",
      "7        negative   negative  0.9999   True  \n",
      "8        positive   positive  1.0000   True  \n",
      "9        negative   negative  1.0000   True  \n",
      "10       positive   positive  0.9986   True  \n",
      "11       negative   negative  0.9998   True  \n",
      "12       negative   negative  1.0000   True  \n",
      "13       positive   negative  0.9999  False  \n",
      "14       positive   negative  0.8979  False  \n",
      "15       positive   positive  1.0000   True  \n",
      "16       negative   negative  1.0000   True  \n",
      "17       negative   negative  1.0000   True  \n",
      "18       positive   positive  1.0000   True  \n",
      "19       negative   negative  1.0000   True  \n",
      "20       positive   positive  1.0000   True  \n",
      "21       negative   negative  1.0000   True  \n",
      "22       negative   negative  1.0000   True  \n",
      "23       negative   negative  1.0000   True  \n",
      "24       positive   positive  1.0000   True  \n",
      "25       negative   negative  0.9999   True  \n",
      "26       negative   negative  1.0000   True  \n",
      "27       negative   negative  1.0000   True  \n",
      "28       negative   negative  1.0000   True  \n",
      "29       negative   negative  1.0000   True  \n",
      "30       positive   positive  1.0000   True  \n",
      "31       positive   positive  0.9995   True  \n",
      "32       positive   positive  1.0000   True  \n",
      "33       positive   positive  1.0000   True  \n",
      "34       positive   positive  1.0000   True  \n",
      "35       negative   negative  1.0000   True  \n",
      "36       negative   negative  1.0000   True  \n",
      "37       negative   negative  1.0000   True  \n",
      "38       negative   negative  1.0000   True  \n",
      "39       negative   negative  1.0000   True  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18325/442955671.py:75: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: (g[\"label_attendue\"] == g[\"prediction\"]).mean())\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Benchmark du modÃ¨le ONNX int8 sur les tweets difficiles.\")\n",
    "    parser.add_argument(\"--model\", type=Path, default=DEFAULT_MODEL_PATH, help=\"Chemin du modÃ¨le ONNX (int8).\")\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=BATCH_SIZE, help=\"Taille de batch pour l'infÃ©rence ONNX.\")\n",
    "    parser.add_argument(\"--max-length\", type=int, default=MAX_LENGTH, help=\"Longueur max de sÃ©quence pour le tokenizer.\")\n",
    "    if \"__file__\" in globals():\n",
    "        args = parser.parse_args()\n",
    "    else:\n",
    "        args = parser.parse_args(args=[])\n",
    "\n",
    "    if not args.model.exists():\n",
    "        raise FileNotFoundError(f\"ModÃ¨le introuvable: {args.model}\")\n",
    "\n",
    "    os.environ.setdefault(\"CUDA_VISIBLE_DEVICES\", \"\")\n",
    "\n",
    "    print(f\"Chargement du modÃ¨le ONNX: {args.model}\")\n",
    "    session = ort.InferenceSession(\n",
    "        str(args.model),\n",
    "        providers=[\"CPUExecutionProvider\"],\n",
    "    )\n",
    "\n",
    "    effective_batch = choose_batch_size(session, args.batch_size)\n",
    "\n",
    "    tokenizer = load_tokenizer()\n",
    "    label_map = load_label_map()\n",
    "\n",
    "    print(f\"\\nÃ‰valuation sur {len(hard_tweets_dataset)} tweets difficiles...\")\n",
    "    df = evaluate_dataset(\n",
    "        session=session,\n",
    "        tokenizer=tokenizer,\n",
    "        label_map=label_map,\n",
    "        dataset=hard_tweets_dataset,\n",
    "        batch_size=effective_batch,\n",
    "        max_length=args.max_length,\n",
    "    )\n",
    "    if not df.empty:\n",
    "        print(\"\\nRÃ©sultats dÃ©taillÃ©s :\")\n",
    "        print(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d7531d",
   "metadata": {},
   "source": [
    "# Testing on our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deba6423",
   "metadata": {},
   "source": [
    "We will reproduce the same test dataset used to evaluate the base distilbert model to see if there is a drop in performance or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5f7748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ Accuracy globale (pos/neg) : 0.8235\n",
      "F1 score: 0.8225\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data (same split as notebook_04)\n",
    "df = pd.read_csv(\n",
    "    \"../../sentiment140/training.1600000.processed.noemoticon.csv\",\n",
    "    encoding=\"latin-1\",\n",
    "    header=None,\n",
    "    names=[\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"tweet\"],\n",
    ")\n",
    "\n",
    "df = df[[\"sentiment\", \"tweet\"]]\n",
    "df_negatifs = df[df[\"sentiment\"] == 0].sample(20000, random_state=42)\n",
    "df_positifs = df[df[\"sentiment\"] == 4].sample(20000, random_state=42)\n",
    "df = pd.concat([df_negatifs, df_positifs]).reset_index(drop=True)\n",
    "df[\"sentiment\"] = df[\"sentiment\"].replace(4, 1)\n",
    "\n",
    "texts = df[\"tweet\"].astype(str).tolist()\n",
    "labels = df[\"sentiment\"].astype(\"float32\").to_numpy()\n",
    "\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
    "    texts,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels,\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp,\n",
    "    y_tmp,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=y_tmp,\n",
    ")\n",
    "\n",
    "test_df = pd.DataFrame({\"tweet\": X_test})\n",
    "test_df[\"label\"] = np.where(y_test == 1, \"positive\", \"negative\")\n",
    "test_df[\"label\"].value_counts()\n",
    "\n",
    "# Build dataset for evaluation\n",
    "test_dataset = [\n",
    "    {\"category\": \"sentiment140\", \"tweet\": row.tweet, \"label\": row.label}\n",
    "    for row in test_df.itertuples(index=False)\n",
    "]\n",
    "\n",
    "if not DEFAULT_MODEL_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Modele introuvable: {DEFAULT_MODEL_PATH}\")\n",
    "\n",
    "os.environ.setdefault(\"CUDA_VISIBLE_DEVICES\", \"\")\n",
    "session = ort.InferenceSession(\n",
    "    str(DEFAULT_MODEL_PATH),\n",
    "    providers=[\"CPUExecutionProvider\"],\n",
    ")\n",
    "\n",
    "effective_batch = choose_batch_size(session, BATCH_SIZE)\n",
    "tokenizer = load_tokenizer()\n",
    "label_map = load_label_map()\n",
    "\n",
    "df_eval = evaluate_dataset(\n",
    "    session=session,\n",
    "    tokenizer=tokenizer,\n",
    "    label_map=label_map,\n",
    "    dataset=test_dataset,\n",
    "    batch_size=effective_batch,\n",
    "    max_length=MAX_LENGTH,\n",
    "    show_category_accuracy=False,\n",
    ")\n",
    "\n",
    "positive_label = \"positive\"\n",
    "tp = ((df_eval[\"label_attendue\"] == positive_label) & (df_eval[\"prediction\"] == positive_label)).sum()\n",
    "fp = ((df_eval[\"label_attendue\"] != positive_label) & (df_eval[\"prediction\"] == positive_label)).sum()\n",
    "fn = ((df_eval[\"label_attendue\"] == positive_label) & (df_eval[\"prediction\"] != positive_label)).sum()\n",
    "denom = (2 * tp + fp + fn)\n",
    "f1 = (2 * tp / denom) if denom else 0.0\n",
    "\n",
    "print(f\"F1 score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.p7venv)",
   "language": "python",
   "name": "p7venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
